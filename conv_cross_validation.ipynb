{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neural_network.layer import *\n",
    "from neural_network.net import *\n",
    "from queue import Queue\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from neural_network.trainutils import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "face_dir = os.path.join(current_dir, \"cmu+face+images\", \"faces\")\n",
    "dataset = Dataset(face_dir, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 120, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, _, test_dataset = train_test_split(dataset, (0.8, 0.0, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 120, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[500][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 120, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = train_dataset[0][0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[ 0.89356498,  0.88204423,  0.70186609, ..., -0.07287527,\n",
       "           -0.14926768,  0.06709001],\n",
       "          [ 0.87623038,  0.85418384,  0.7840018 , ..., -0.08577082,\n",
       "           -0.10870554,  0.16428764],\n",
       "          [ 1.06071743,  1.06291336,  1.05501475, ...,  0.01652978,\n",
       "           -0.20427228, -0.32743861],\n",
       "          ...,\n",
       "          [-0.96958661, -1.06568854, -0.90124237, ..., -0.79624408,\n",
       "           -0.80406965, -0.78658602],\n",
       "          [-0.96819614, -1.03387179, -0.93275801, ..., -0.78640354,\n",
       "           -0.76315872, -0.76266749],\n",
       "          [-0.84390258, -0.84255993, -0.55252975, ..., -0.81278744,\n",
       "           -0.80262334, -0.78879583]]]]),\n",
       " array([[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_shape = np.ndarray([1, 1, 3, 3])\n",
    "pad = 1\n",
    "stride = 1\n",
    "\n",
    "conv1 = Conv2D(kernel_shape, pad, stride, layer_id=1) # 120x128\n",
    "maxpool1 = MaxPool2D(2, 0, 2, conv1) # 60x64\n",
    "relu1 = ReLU(maxpool1)\n",
    "\n",
    "conv2 = Conv2D(kernel_shape, pad, stride, relu1, layer_id=2)\n",
    "maxpool2 = MaxPool2D(2, 0, 2, conv2) # 30x32\n",
    "relu2 = ReLU(maxpool2)\n",
    "\n",
    "conv3 = Conv2D(kernel_shape, pad, stride, relu2, layer_id=3)\n",
    "maxpool3 = MaxPool2D(2, 0, 2, conv3) # 15x16\n",
    "relu3 = ReLU(maxpool3)\n",
    "\n",
    "flatten = Flatten(relu3)\n",
    "\n",
    "linear = Linear(15*16, len(dataset.keys), flatten)\n",
    "softmax_layer = Softmax(linear)\n",
    "loss_layer = CrossEntropy(softmax_layer)\n",
    "\n",
    "model = NeuralNetwork(conv1, softmax_layer, loss_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 3, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward order:\n",
      "Conv2D 1: (1, 1, 3, 3), pad=1, stride=1\n",
      "MaxPool2D: (2, 2), pad=0, stride=2\n",
      "ReLU\n",
      "Conv2D 2: (1, 1, 3, 3), pad=1, stride=1\n",
      "MaxPool2D: (2, 2), pad=0, stride=2\n",
      "ReLU\n",
      "Conv2D 3: (1, 1, 3, 3), pad=1, stride=1\n",
      "MaxPool2D: (2, 2), pad=0, stride=2\n",
      "ReLU\n",
      "Flatten\n",
      "Linear: (240, 1) -> (4, 1)\n",
      "Softmax\n",
      "CrossEntropy\n",
      "\n",
      "Backward order:\n",
      "CrossEntropy\n",
      "Softmax\n",
      "Linear: (240, 1) -> (4, 1)\n",
      "Flatten\n",
      "ReLU\n",
      "MaxPool2D: (2, 2), pad=0, stride=2\n",
      "Conv2D 3: (1, 1, 3, 3), pad=1, stride=1\n",
      "ReLU\n",
      "MaxPool2D: (2, 2), pad=0, stride=2\n",
      "Conv2D 2: (1, 1, 3, 3), pad=1, stride=1\n",
      "ReLU\n",
      "MaxPool2D: (2, 2), pad=0, stride=2\n",
      "Conv2D 1: (1, 1, 3, 3), pad=1, stride=1\n"
     ]
    }
   ],
   "source": [
    "print(\"Forward order:\")\n",
    "for layer in model._forward_order:\n",
    "    print(layer)\n",
    "\n",
    "print(\"\\nBackward order:\")\n",
    "for layer in model._backward_order:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "results = k_fold_cross_validation(10, model, train_dataset, epochs=50, lr=1e-3, validation_period=5, seed=585)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mloss_array\u001b[49m[:\u001b[38;5;241m50\u001b[39m])\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage loss per epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_array' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_array[:50])\n",
    "plt.title(\"Average loss per epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average Loss\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(dataset.label, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['left' 'right' 'straight' 'up']\n",
      "[157 155 156 156]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.keys[unique])\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m my_img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest/woman_straight.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#my_img = np.array(my_img).reshape(-1, 1)\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmy_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Image' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "my_img = Image.open(\"test/woman_straight.jpg\").convert(\"L\")\n",
    "my_img = np.array(my_img)#.reshape(-1, 1)\n",
    "my_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_img\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\repos\\face_orientation_585\\neural_network\\net.py:27\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_order[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Loss): \u001b[38;5;66;03m# regular layer\u001b[39;00m\n",
      "File \u001b[1;32mf:\\repos\\face_orientation_585\\neural_network\\layer.py:127\u001b[0m, in \u001b[0;36mConv2D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m        Performs a forward convolution.\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m        - out: previous layer convolved.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     batch_size, in_channels, in_height, in_width \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    129\u001b[0m     out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_filters\n\u001b[0;32m    130\u001b[0m     out_height \u001b[38;5;241m=\u001b[39m ((in_height \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "model.forward(my_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
